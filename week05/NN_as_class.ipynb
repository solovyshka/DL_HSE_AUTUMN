{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# О том, как учат сложные сетки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "keras, L = tf.keras, tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке немного поработаем с градусами по цельсию и фаренгейту! Снова попробуем восстановить формулу \n",
    "\n",
    "$$ f = c \\times 1.8 + 32 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-40.0 degrees Celsius = -40.0 degrees Fahrenheit\n",
      "-10.0 degrees Celsius = 14.0 degrees Fahrenheit\n",
      "0.0 degrees Celsius = 32.0 degrees Fahrenheit\n",
      "8.0 degrees Celsius = 46.0 degrees Fahrenheit\n",
      "15.0 degrees Celsius = 59.0 degrees Fahrenheit\n",
      "22.0 degrees Celsius = 72.0 degrees Fahrenheit\n",
      "38.0 degrees Celsius = 100.0 degrees Fahrenheit\n"
     ]
    }
   ],
   "source": [
    "celsius    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
    "fahrenheit = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)\n",
    "\n",
    "for i,c in enumerate(celsius):\n",
    "    print(\"{} degrees Celsius = {} degrees Fahrenheit\".format(c, fahrenheit[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# транспонировали выборку\n",
    "x_train = celsius[:,None]\n",
    "y_train = fahrenheit[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Как мы обучались до этого \n",
    "\n",
    "На Keras было всё совсем просто. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 46ms/sample - loss: 1914.4365 - val_loss: 8692.5264\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1913.1516 - val_loss: 8686.5801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256e7228f08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( )\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После мы сказали, что иногда хочется собирать более сложные модели, а ещё жёстко контролировать обучение, и посмотрели на Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(tf.random.normal([1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Наша модель\n",
    "def linear_regression(x):\n",
    "    return a + b*x\n",
    "\n",
    "# Ошибка для модели\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean((y_pred-y_true)**2)\n",
    "\n",
    "# оптимизатор \n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# процесс оптимизации\n",
    "def model_train(X, Y):\n",
    "\n",
    "    # находим loss и пробрасываем градиент\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = linear_regression(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    # Вычисляем градиенты\n",
    "    gradients = g.gradient(loss, [a, b])\n",
    "    \n",
    "    # Обновляем веса a и b в ходе одной итерации спуска \n",
    "    optimizer.apply_gradients(zip(gradients, [a, b]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 1040.500732, a: -0.090210, b: 2.379928\n",
      "step: 10, loss: 948.990540, a: 0.517278, b: 2.063241\n",
      "step: 20, loss: 913.200867, a: 1.115780, b: 2.058189\n",
      "step: 30, loss: 878.761108, a: 1.702886, b: 2.053235\n",
      "step: 40, loss: 845.620239, a: 2.278815, b: 2.048374\n",
      "step: 50, loss: 813.729370, a: 2.843778, b: 2.043607\n",
      "step: 60, loss: 783.041138, a: 3.397985, b: 2.038929\n",
      "step: 70, loss: 753.510559, a: 3.941639, b: 2.034341\n",
      "step: 80, loss: 725.093628, a: 4.474943, b: 2.029841\n",
      "step: 90, loss: 697.748535, a: 4.998094, b: 2.025425\n"
     ]
    }
   ],
   "source": [
    "#Обучение\n",
    "epochs = 100 # число эпох \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Делаем щаг градиентного спуска \n",
    "    model_train(celsius, fahrenheit)\n",
    "    \n",
    "    # Каждую сотую итерацию следим за тем, что произошло\n",
    "    if i%10 == 0:\n",
    "        y_pred = linear_regression(celsius)\n",
    "        loss_val = mean_square(y_pred, fahrenheit)\n",
    "        print(\"step: %i, loss: %f, a: %f, b: %f\" % (i, loss_val, a.numpy(), b.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Как обычно обучаются на Tensorflow \n",
    "\n",
    "Для того, чтобы было удобнее, модели заворачивают в полноценные классы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "class Super_puper_neural_net(Model):\n",
    "    \n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(Super_puper_neural_net, self).__init__()\n",
    "        self.fc1 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           activation='relu', trainable=True)\n",
    "        self.fc2 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           trainable=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[  0.        ],\n",
       "       [  0.        ],\n",
       "       [  0.        ],\n",
       "       [-14.08335521],\n",
       "       [-26.40629101],\n",
       "       [-38.72922682],\n",
       "       [-66.89593723]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Super_puper_neural_net(1)\n",
    "model.encode(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = Super_puper_neural_net(1)\n",
    "model2 = Super_puper_neural_net(1)\n",
    "\n",
    "x1 = model1.encode(x_train)\n",
    "x2 = model2.encode(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(1, 1) dtype=float64, numpy=array([[1.48600645]])>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float64, numpy=array([0.])>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(1, 1) dtype=float64, numpy=array([[-1.18466471]])>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float64, numpy=array([0.])>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Список из переменных\n",
    "model.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно легко подменять одни переменные какими-нибудь своими. Это довольно удобно, когда хочется позаимствовать чужие веса. В будущем мы будем этим активно заниматься. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка для модели\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean((y_pred-y_true)**2)\n",
    "\n",
    "# оптимизатор \n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# процесс оптимизации\n",
    "def model_train(X, Y):\n",
    "\n",
    "    # находим loss и пробрасываем градиент\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model.encode(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    # Вычисляем градиенты\n",
    "    gradients = g.gradient(loss, model.variables)\n",
    "    \n",
    "    # Обновляем веса a и b в ходе одной итерации спуска \n",
    "    optimizer.apply_gradients(zip(gradients, model.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 17571.846658\n",
      "step: 10, loss: nan\n",
      "step: 20, loss: nan\n",
      "step: 30, loss: nan\n",
      "step: 40, loss: nan\n",
      "step: 50, loss: nan\n",
      "step: 60, loss: nan\n",
      "step: 70, loss: nan\n",
      "step: 80, loss: nan\n",
      "step: 90, loss: nan\n"
     ]
    }
   ],
   "source": [
    "#Обучение\n",
    "epochs = 100 # число эпох \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Делаем щаг градиентного спуска \n",
    "    model_train(x_train, y_train)\n",
    "    \n",
    "    # Каждую сотую итерацию следим за тем, что произошло\n",
    "    if i%10 == 0:\n",
    "        y_pred = model.encode(x_train)\n",
    "        loss_val = mean_square(y_pred, y_train)\n",
    "        print(\"step: %i, loss: %f\" % (i, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Свой слой на Tensorflow для Keras\n",
    "\n",
    "Новые слои можно писать на основе керасовского класса `Layer`. Если прописать `help(tf.keras.layers.Layer)`, можно почитать про него. Если в кратце, нужно реализовать три части: \n",
    "\n",
    "* Конструктор, в нём мы описываем гиперпараметры \n",
    "* Метод `build`, в которм мы описываем все переменные \n",
    "* Метод `call`, который делает forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(L.Layer):\n",
    "    \n",
    "    # Задаём консруктор \n",
    "    def __init__(self, units=32):\n",
    "        super(MyLinear, self).__init__()  # чтобы коректно унаследовались методы\n",
    "        self.units = units                # число нейронов\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # add_weight внутри build то же самое что и Variable, но совместимо с Keras\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "\n",
    "    # Применение \n",
    "    def call(self, inputs):\n",
    "        # сразу делаем и линейное преобразование и ReLU (а почему бы и нет)\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(MyLinear())  # добавили свой слой! \n",
    "model.add(L.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam( )\n",
    "model.compile(loss='mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 0s 53ms/sample - loss: 1740.3874 - val_loss: 7942.8867\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1735.8881 - val_loss: 7928.0667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256e8c05588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.2, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогии с помощью класса `Model` можно делать полноценные слои-модели. Этим мы тоже будем позже заниматься. Почитать про свои слои и модели можно подробнее [вот тут, в документации.](https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

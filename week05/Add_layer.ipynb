{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постепенное наращивание сети \n",
    "\n",
    "Попробуем сделать в tensorflow штуку посложнее. А именно, постепенно нарастить сетку, добавляя в неё новые слои и нейроны. Всё будем делать в матричном виде. Сначала подгрузим пару библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для визуализации обучения \n",
    "def visualize(l1,l2, h1, h2):\n",
    "    plt.figure(figsize=(20,5)) \n",
    "    epo_range = range(1,len(h1)+1)\n",
    "    tick_range = range(1,len(h1)+1,2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Learning loss')\n",
    "    plt.plot(epo_range,l1, label='train set')\n",
    "    plt.plot(epo_range,l2, label='valid set')\n",
    "    plt.grid()\n",
    "    plt.xticks(tick_range)\n",
    "    plt.legend(title = 'Loss at:')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Learning accuracy')\n",
    "    plt.plot(epo_range,h1, label='train set')\n",
    "    plt.plot(epo_range,h2, label='valid set')\n",
    "    plt.grid()\n",
    "    plt.xticks(tick_range)\n",
    "    plt.ylim(0, 1.)\n",
    "    plt.legend(title = 'Accuracy at:')\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras  \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# внутри keras уже есть набор данных, подгрузим его \n",
    "def load_dataset( ):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # нормализация матриц\n",
    "    X_train = X_train.astype(np.float32) / 255.\n",
    "    X_test = X_test.astype(np.float32) / 255.\n",
    "    \n",
    "    # вытягиваем матрицы [n,28,28] в вектрора [n,28**2]\n",
    "    X_train = X_train.reshape(X_train.shape[0],28**2)\n",
    "    X_test = X_test.reshape(X_test.shape[0],28**2)\n",
    "    \n",
    "    # сделаем OHE для таргета\n",
    "    y_train = keras.utils.to_categorical(y_train).astype(np.float32)\n",
    "    y_test = keras.utils.to_categorical(y_test).astype(np.float32)\n",
    "\n",
    "    # последние 10000 примеров из трэйна оставим для валидации\n",
    "    X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size=0.15, stratify=y_train)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свой небольшой уютный рукописный генератор батчей для обучения. Как думаете чего в нём не хватает? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(X, y, batch_size):\n",
    "    n_batches = int(X.shape[0]/batch_size) + 1\n",
    "    for batch_idx in range(n_batches):\n",
    "        indices = (batch_idx*batch_size, min(X.shape[0], (batch_idx+1)*batch_size))\n",
    "        yield X[indices[0]:indices[1]], y[indices[0]:indices[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ исправьте в генераторе это небольшой недочёт. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем своего трёхслойного монстра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_simple():\n",
    "    \n",
    "    def __init__(self, L1, L2, L3, learning_rate):\n",
    "        self.W1 = tf.Variable(tf.random.truncated_normal([784, L1], stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "        self.W2 = tf.Variable(tf.random.truncated_normal([L1, L2], stddev=0.1))\n",
    "        self.b2 = tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "        self.W3 = tf.Variable(tf.random.truncated_normal([L2, L3], stddev=0.1))\n",
    "        self.b3 = tf.Variable(tf.zeros([L3]))\n",
    "        self.opt = tf.optimizers.Adam(learning_rate)\n",
    "        \n",
    "    def generate_prediction_logits(self,X_train):\n",
    "        # Определеям саму модель\n",
    "        Y1 = tf.nn.relu(tf.matmul(X_train, self.W1) + self.b1)\n",
    "        Y2 = tf.nn.relu(tf.matmul(Y1, self.W2) + self.b2)\n",
    "        Ylogits = tf.matmul(Y2, self.W3) + self.b3\n",
    "        return Ylogits\n",
    "    \n",
    "    def make_loss(self,X_train,y_train):\n",
    "        Ylogits = self.generate_prediction_logits(X_train)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=y_train)\n",
    "        return tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    @tf.function\n",
    "    def make_learning_step(self,X_train,y_train):\n",
    "        # находим loss и пробрасываем градиент\n",
    "        with tf.GradientTape() as g:\n",
    "            loss = self.make_loss(X_train, y_train)\n",
    "        gradients = g.gradient(loss, [self.W1,self.W2,self.W3,self.b1, self.b2,\n",
    "                                     self.b3])\n",
    "        self.opt.apply_gradients(zip(gradients, [self.W1,self.W2,self.W3,self.b1, self.b2,\n",
    "                                     self.b3]))\n",
    "        return gradients\n",
    "    \n",
    "    def model_acc(self,x_train,y_train):\n",
    "        Ylogits = self.generate_prediction_logits(x_train)\n",
    "        Y = tf.nn.softmax(Ylogits)\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(y_train, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаём модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1, L2, L3 = 4, 2, 10\n",
    "learning_rate = 0.003\n",
    "\n",
    "Our_Model = model_simple(L1,L2,L3,learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модельку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем писать значения метрик в вектора \n",
    "loss_test, loss_train  = [ ], [ ] \n",
    "acc_test, acc_train = [ ], [ ]\n",
    "\n",
    "for i in tqdm(range(n_epochs)):\n",
    "\n",
    "    num_batches = (X_train.shape[0] / batch_size) + 1\n",
    "    \n",
    "    # сгенерировали батчи \n",
    "    batch_gen = batches_generator(X_train, y_train, batch_size)\n",
    "    \n",
    "    # пошёл цикл по батчам \n",
    "    for X_batch, y_batch in batch_gen:\n",
    "        # вся логика обучения зашита в методе\n",
    "        Our_Model.make_learning_step(X_batch,y_batch)\n",
    "    \n",
    "    # посмотрим на качество модели на трэйне и валидации\n",
    "    loss_train.append(Our_Model.make_loss(X_train,y_train))\n",
    "    loss_test.append(Our_Model.make_loss(X_val,y_val))\n",
    "    \n",
    "    acc_train.append(Our_Model.model_acc(X_train,y_train))\n",
    "    acc_test.append(Our_Model.model_acc(X_val,y_val))\n",
    "    \n",
    "    # визуализируем\n",
    "    visualize(loss_train, loss_test, acc_train, acc_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть что за веса получилсь можно вот так: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Our_Model.W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сохраним получившиеся веса, например в виде numpy массивов, чтобы в случае чего мы могли бы их подгрузить. Модели можно сохранять ещё и как графы вычислений. Но про это мы поговорим позже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Веса с первого слоя \n",
    "weight_1_save = Our_Model.W1.numpy() \n",
    "bias_1_save = Our_Model.b1.numpy()\n",
    "\n",
    "np.save('weight_1_save.npy', weight_1_save)\n",
    "np.save('bias_1_save.npy', bias_1_save)\n",
    "\n",
    "# Веса второго слоя\n",
    "weight_2_save = Our_Model.W2.numpy()\n",
    "bias_2_save = Our_Model.b2.numpy()\n",
    "\n",
    "np.save('weight_2_save.npy', weight_2_save)\n",
    "np.save('bias_2_save.npy', bias_2_save)\n",
    "\n",
    "# Веса третьего слоя \n",
    "weight_3_save = Our_Model.W3.numpy()\n",
    "bias_3_save = Our_Model.b3.numpy()\n",
    "\n",
    "np.save('weight_3_save.npy', weight_3_save)\n",
    "np.save('bias_3_save.npy', bias_3_save)\n",
    "\n",
    "# загрузить веса назад можно следующим способом\n",
    "bias_1_save = np.load('bias_1_save.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер мы хотим научиться добавлять в уже обученную сетку новые нейроны. Что такое новый нейрон, с точки зрения матриц? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проинициализируйте новый нейрон :) \n",
    "# И дообучите сетку\n",
    "\n",
    "# Вроде бы звучит просто..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
